ğŸ· Trabalho de MineraÃ§Ã£o de Dados â€” SeleÃ§Ã£o de Atributos
ğŸ§  DescriÃ§Ã£o do Projeto

Este trabalho aplica tÃ©cnicas de seleÃ§Ã£o de atributos em tarefas de classificaÃ§Ã£o e regressÃ£o utilizando o Wine Quality Dataset.
O objetivo principal Ã© explorar como diferentes mÃ©todos de feature selection impactam no desempenho e na interpretabilidade dos modelos de Machine Learning.

ğŸ¯ Objetivos

ğŸ”¹ ClassificaÃ§Ã£o: prever a qualidade do vinho (binÃ¡ria: bom ou ruim)

ğŸ”¹ RegressÃ£o: prever o valor do pH do vinho

ğŸ”¹ Comparar 4 mÃ©todos de seleÃ§Ã£o de atributos

ğŸ”¹ Analisar o trade-off entre performance e interpretabilidade

ğŸ”¹ Avaliar ganhos em eficiÃªncia computacional

ğŸ“Š Dataset

Fonte: UCI Machine Learning Repository â€” Wine Quality Dataset

ğŸ§ª InstÃ¢ncias: 1.599 amostras de vinho tinto

âš™ï¸ Atributos: 11 caracterÃ­sticas fÃ­sico-quÃ­micas

ğŸ¯ Targets:

quality_class â†’ classificaÃ§Ã£o binÃ¡ria

0 = qualidade < 7

1 = qualidade â‰¥ 7

pH â†’ regressÃ£o (valor contÃ­nuo)

ğŸ§° Tecnologias Utilizadas

Linguagem: Python 3.12+

Bibliotecas:

ğŸ§© scikit-learn â€” Modelos e seleÃ§Ã£o de features

ğŸ“Š pandas â€” ManipulaÃ§Ã£o de dados

ğŸ”¢ numpy â€” ComputaÃ§Ã£o numÃ©rica

ğŸ¨ matplotlib & seaborn â€” VisualizaÃ§Ãµes

âš–ï¸ imbalanced-learn â€” Balanceamento de classes (SMOTE)

âš—ï¸ MÃ©todos de SeleÃ§Ã£o Implementados
MÃ©todo	DescriÃ§Ã£o	Tipo de RelaÃ§Ã£o
1. SelectKBest (ANOVA F-value)	SeleÃ§Ã£o baseada em teste estatÃ­stico F	Linear
2. SelectKBest (Mutual Information)	Baseado em teoria da informaÃ§Ã£o	NÃ£o-linear
3. RFE (Recursive Feature Elimination)	EliminaÃ§Ã£o recursiva com base na importÃ¢ncia do modelo	Depende do modelo
4. Feature Importance (Random Forest)	ImportÃ¢ncia intrÃ­nseca de cada feature	Qualquer
ğŸ§¹ PrÃ©-Processamento
ğŸ”§ Limpeza

RemoÃ§Ã£o de 240 duplicatas

VerificaÃ§Ã£o de valores nulos

ğŸ§ª Engenharia de Features

CriaÃ§Ã£o do target binÃ¡rio para classificaÃ§Ã£o

NormalizaÃ§Ã£o com StandardScaler

âš–ï¸ Balanceamento

AplicaÃ§Ã£o de SMOTE para equilibrar classes

Melhorou a detecÃ§Ã£o de vinhos de alta qualidade

ğŸ§¬ Metodologia Experimental
ğŸ“‚ DivisÃ£o dos Dados

70% treino / 30% teste

EstratificaÃ§Ã£o para classificaÃ§Ã£o

ValidaÃ§Ã£o cruzada: 5-fold

ğŸ¤– Modelos Base

ClassificaÃ§Ã£o: RandomForestClassifier

RegressÃ£o: RandomForestRegressor

ğŸ“ˆ MÃ©tricas de AvaliaÃ§Ã£o
Tarefa	MÃ©tricas
ClassificaÃ§Ã£o	AcurÃ¡cia, Precision, Recall, F1-Score
RegressÃ£o	MSE, RÂ²
ğŸ§¾ Resultados Principais
ğŸ”¹ ClassificaÃ§Ã£o
MÃ©todo	AcurÃ¡cia	NÂº Features
Baseline	87.75%	11
Mutual Information	ğŸ¥‡ 88.97%	5
Feature Importance	87.25%	5
ANOVA (F-Value)	87.25%	5
RFE	87.25%	5
ğŸ”¹ RegressÃ£o
MÃ©todo	RÂ²	NÂº Features
Baseline	98.81%	10
Feature Importance	ğŸ¥‡ 99.46%	4
Mutual Information	98.92%	5
F-Regression (ANOVA)	62.57%	5
ğŸ” Insights e AnÃ¡lises
â­ Features Mais Importantes
ğŸ§© ClassificaÃ§Ã£o
Ranking	Feature	ImportÃ¢ncia
ğŸ¥‡	Ãlcool	17.6%
ğŸ¥ˆ	Sulfatos	13.0%
ğŸ¥‰	Acidez VolÃ¡til	10.9%
ğŸ§ª RegressÃ£o
Ranking	Feature
ğŸ¥‡	Acidez Fixa (99.8%)
ğŸ¥ˆ	Densidade
ğŸ¥‰	Ãlcool
âš™ï¸ EficiÃªncia Computacional

â±ï¸ ReduÃ§Ã£o de 40% no tempo de treinamento

ğŸ“‰ Modelos mais simples

ğŸ’¡ ManutenÃ§Ã£o (ou melhoria) da performance

ğŸ§­ ConclusÃµes
âœ… Pontos Fortes

ManutenÃ§Ã£o da performance com menos atributos

Modelos mais interpretÃ¡veis

Ganhos expressivos em eficiÃªncia computacional

SMOTE balanceou efetivamente as classes

ğŸ“š Aprendizados

A seleÃ§Ã£o de atributos nem sempre melhora a acurÃ¡cia, mas traz ganhos de interpretaÃ§Ã£o e eficiÃªncia

Cada tipo de problema demanda um mÃ©todo diferente de seleÃ§Ã£o

O balanceamento Ã© essencial em dados desbalanceados

A interpretabilidade Ã© tÃ£o importante quanto o desempenho

ğŸ‘¨â€ğŸ’» Autor

Nome: Samir Lopes Rosa
Disciplina: MineraÃ§Ã£o de Dados
InstituiÃ§Ã£o: FATEC â€” Franca/SP

ğŸ“š ReferÃªncias

UCI Machine Learning Repository â€” Wine Quality Dataset

Scikit-learn Documentation

IMB Learn â€” SMOTE Documentation