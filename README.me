Trabalho de Minera√ß√£o de Dados - Sele√ß√£o de Atributos

Descri√ß√£o do Projeto

Este trabalho acad√™mico aplica t√©cnicas de sele√ß√£o de atributos para tarefas de classifica√ß√£o e regress√£o utilizando o Wine Quality Dataset. O objetivo principal √© explorar como diferentes m√©todos de sele√ß√£o de features impactam no desempenho e interpretabilidade de modelos de machine learning.

Objetivos:

Classifica√ß√£o: Prever a qualidade do vinho (bin√°ria: bom/ruim)

Regress√£o: Prever o pH do vinho

Comparar 4 m√©todos de sele√ß√£o de atributos

Analisar trade-off entre performance e interpretabilidade

Avaliar ganhos em efici√™ncia computacional

Dataset

Fonte: UCI Machine Learning Repository - Wine Quality Dataset
Inst√¢ncias: 1.599 amostras de vinho tinto
Atributos: 11 caracter√≠sticas f√≠sico-qu√≠micas
Targets:

quality_class: Classifica√ß√£o bin√°ria (0 = qualidade < 7, 1 = qualidade ‚â• 7)

pH: Regress√£o (valor cont√≠nuo)

Tecnologias Utilizadas:

Python 3.12+

Bibliotecas:

scikit-learn - Modelos de ML e sele√ß√£o de features

pandas - Manipula√ß√£o de dados

numpy - Computa√ß√£o num√©rica

matplotlib & seaborn - Visualiza√ß√µes

imbalanced-learn - Balanceamento de classes (SMOTE)

M√©todos de Sele√ß√£o Implementados:

1. SelectKBest com ANOVA F-value
Sele√ß√£o baseada em teste estat√≠stico F

Ideal para rela√ß√µes lineares

2. SelectKBest com Mutual Information
Captura rela√ß√µes n√£o-lineares

Baseado em teoria da informa√ß√£o

3. RFE (Recursive Feature Elimination)
Elimina√ß√£o recursiva de features

Usa import√¢ncia do modelo

4. Feature Importance (Random Forest)
Baseado na import√¢ncia intr√≠nseca do modelo

Threshold no percentil 70

Pr√©-processamento

Limpeza:

Remo√ß√£o de duplicatas (240 inst√¢ncias)

Verifica√ß√£o de valores nulos

Engenharia de Features:

Cria√ß√£o de target bin√°rio para classifica√ß√£o

Normaliza√ß√£o com StandardScaler

Balanceamento:

Aplica√ß√£o de SMOTE para classe minorit√°ria

Melhora na detec√ß√£o de vinhos de alta qualidade

Metodologia Experimental

Divis√£o dos Dados
Split: 70% treino / 30% teste

Estratifica√ß√£o para classifica√ß√£o

Valida√ß√£o cruzada 5-fold

Modelos Base
Classifica√ß√£o: Random Forest Classifier

Regress√£o: Random Forest Regressor

M√©tricas de Avalia√ß√£o
Classifica√ß√£o: Acur√°cia, Precision, Recall, F1-Score

Regress√£o: MSE, R¬≤

Resultados Principais

Classifica√ß√£o
M√©todo	Acur√°cia	N¬∞ Features
Baseline	87.75%	11
Mutual Information	88.97%	5
Feature Importance	87.25%	5
ANOVA	87.25%	5
RFE	87.25%	5

Regress√£o
M√©todo	R¬≤	N¬∞ Features
Baseline	98.81%	10
Feature Importance	99.46%	4
Mutual Information	98.92%	5
F-Regression	62.57%	5

Insights e An√°lises

Features Mais Importantes
Classifica√ß√£o:

ü•á √Ålcool (17.6%)

ü•à Sulfatos (13.0%)

ü•â Acidez Vol√°til (10.9%)

Regress√£o:

ü•á Acidez Fixa (99.8%)

ü•à Densidade

ü•â √Ålcool

Efici√™ncia Computacional
Redu√ß√£o de 40% no tempo de treinamento

Manuten√ß√£o ou melhoria da performance

Modelos mais simples e interpret√°veis

Conclus√µes

Pontos Fortes:
Manuten√ß√£o da performance com menos features

Melhoria na interpretabilidade dos modelos

Ganhos significativos em efici√™ncia computacional

Balanceamento efetivo com SMOTE


Aprendizados:

Sele√ß√£o n√£o garante melhor acur√°cia, mas traz outros benef√≠cios

Diferentes problemas exigem diferentes m√©todos de sele√ß√£o

Balanceamento √© crucial para classifica√ß√£o desbalanceada

Interpretabilidade tem valor pr√°tico significativo

Autor
Nome: Samir Lopes Rosa
Disciplina: Minera√ß√£o de Dados
Professor: Jaqueline Brigladori Pugliesi
Institui√ß√£o: FATEC/Franca-SP

Refer√™ncias

UCI Wine Quality Dataset

Scikit-learn Documentation

IMBLearn Documentation (SMOTE)